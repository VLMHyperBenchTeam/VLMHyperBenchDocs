# Сравнительный анализ

Анализ существующих решений и подходов в области оценки VLM, а также обоснование выбранной архитектуры VLMHyperBench.

## 1. Архитектура и Развертывание
*   **Микропакетная архитектура**: Утверждена архитектура с изоляцией через Docker/Singularity. Это решает проблему конфликтов зависимостей, характерную для монолитных фреймворков.
*   **EnvManager**: Внедрена концепция EnvManager для абстракции среды выполнения (Docker, Pod, venv), что позволяет запускать бенчмарки как локально, так и в облаке/HPC без изменения кода.
*   **Динамические зависимости**: Разработана стратегия динамической установки зависимостей, позволяющая гибко настраивать окружение под конкретные этапы (Inference, Eval) без пересборки базовых образов.

## 2. Интеграция HuggingFace и vLLM
*   **Абстракция ModelInterface**: Необходима для унификации API различных библиотек.
*   **HuggingFace**: Используется для максимальной совместимости и отладки. Требует ручного управления процессорами изображений.
*   **vLLM**: Используется для production-инференса (высокая скорость, batching). Требует специфичного форматирования `multi_modal_data`.
*   **Backend Selection**: В конфигурацию модели добавлено поле `backend` для выбора движка инференса.

## 3. Анализ EvalScope
*   **Сходства**: EvalScope использует реестровую систему и адаптеры, что подтверждает правильность нашего выбора в пользу модульности.
*   **Интеграция**: Использование существующих бэкендов (VLMEvalKit) — валидная стратегия.
*   **Отличия**: VLMHyperBench отличается более строгой изоляцией (контейнеризация каждого этапа) и специализацией на документарных задачах.

## 4. Лучшие практики оценки VLM
*   **ANLS**: Критически важная метрика для OCR/DocVQA задач.
*   **Нормализация**: Необходима тщательная нормализация текста перед сравнением.
*   **Closed-Set Evaluation**: Для задач классификации рекомендуется использовать перемешивание вариантов ответов.
*   **Прозрачность**: Важно сохранять сырые данные (`answers.csv`) для анализа ошибок.
*   **Многоуровневая агрегация**: Реализовать подсчет метрик на трех уровнях (Global, Document Type, Field Level).
*   **Промпт-инжиниринг**: Интеграция с системами версионирования промптов (Arize Phoenix).

## 5. VLMHyperBench vs EvalScope

| Критерий | VLMHyperBench | EvalScope / VLMEvalKit |
| :--- | :--- | :--- |
| **Изоляция** | Строгая (контейнер на каждый этап) | Мягкая (Conda/Venv) |
| **Специализация** | Документы (OCR, DocVQA) | General VLM Tasks |
| **Агрегация** | Многоуровневая (Field, Doc Type) | Dataset Level |
| **Инференс** | API Wrapper (TTFT, TPOT) | Прямой вызов библиотек |

## Преимущества VLMHyperBench

1.  **Промышленная направленность**: Акцент на точность извлечения данных из документов (паспорта, счета).
2.  **Воспроизводимость**: Использование Docker гарантирует идентичность окружений на разных машинах.
3.  **Гибкость развертывания**: Поддержка не только локального Docker, но и облачных GPU-провайдеров (RunPod).