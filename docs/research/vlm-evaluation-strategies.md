# Стратегии оценки VLM

На основе проведенных исследований мы выделили ключевые стратегии и лучшие практики для оценки Vision Language Models в задачах анализа документов.

## 1. Методология оценки

Оценка VLM сложнее, чем LLM, так как требует проверки понимания визуального контента, а не только генерации текста.

### 1.1. Категории задач
*   **Perception (Восприятие)**: Распознавание объектов, текста (OCR), атрибутов.
    *   *Бенчмарки*: VQAv2, DocVQA, OCRBench.
*   **Reasoning (Рассуждение)**: Логические выводы на основе изображения (MathVista, MMMU).
*   **Hallucination (Галлюцинации)**: Проверка на выдуманные объекты (POPE).

### 1.2. Подходы к генерации ответов
*   **Zero-shot**: Оценка без примеров (наиболее частый сценарий для VLM).
*   **Few-shot**: Добавление примеров (in-context learning) для сложных задач.
*   **Chain-of-Thought (CoT)**: Просьба модели "подумать пошагово" перед ответом (особенно для Math/Reasoning).

## 2. Метрики оценки

### 2.1. Детерминированные метрики
*   **ANLS (Average Normalized Levenshtein Similarity)**: Критически важная метрика для задач DocVQA, позволяющая мягко оценивать ошибки в написании слов, сохраняя при этом строгость к фактическим ошибкам.
    *   *Формула*: `1 - d(pred, gt) / max(len(pred), len(gt))`, с порогом (обычно 0.5).
*   **Exact Match (EM)**: Полное совпадение (после нормализации). Подходит для Multiple Choice.
*   **WER/CER**: Стандартные метрики для оценки качества распознавания текста.

### 2.2. Семантические метрики
*   **BLEU / CIDEr / SPICE**: Традиционные метрики для Image Captioning. Измеряют n-gram перекрытия.
*   **LLM-as-a-Judge**: Использование сильной LLM (GPT-4) для оценки корректности ответа VLM.
    *   *Плюсы*: Понимает синонимы и перефразирования.
    *   *Минусы*: Дорого, зависит от "судьи".

### 2.3. Нормализация текста
Критически важна перед сравнением:
*   Приведение к нижнему регистру.
*   Удаление пунктуации.
*   Конвертация чисел (слова в цифры).

## 3. Стратегии оценки

*   **Closed-Set Evaluation**: Для задач классификации рекомендуется использовать фиксированный набор вариантов ответов с перемешиванием (shuffling) для исключения влияния порядка на выбор модели.
*   **Многоуровневая агрегация**: Метрики должны рассчитываться и агрегироваться на трех уровнях:
    1.  **Global Level**: Общая точность по всему датасету.
    2.  **Document Type Level**: Точность в разрезе типов документов (паспорта, счета, справки).
    3.  **Field Level**: Точность извлечения конкретных полей (ФИО, ИНН, Дата).
*   **Прозрачность**: Сохранять не только итоговую метрику, но и **сырые предсказания** модели (`answers.csv`), чтобы можно было вручную проанализировать ошибки.

## 4. Промпт-инжиниринг

*   **Версионирование**: Использование систем типа Arize Phoenix для трекинга и версионирования промптов.
*   **Динамическая подстановка**: Использование `PromptAdapter` для замены базовых промптов из датасета на оптимизированные версии для конкретных моделей.

## 5. Масштабируемость

*   **Изоляция**: Каждый запуск инференса должен быть изолирован в контейнере для предотвращения конфликтов библиотек (например, разные версии `transformers` или `vLLM`).
*   **Параллелизм**: Асинхронный запуск задач и распределение по доступным GPU воркерам.
*   **Модульность метрик**: Реализовать метрики как отдельные классы с единым интерфейсом `Metric`, чтобы легко добавлять новые (например, ANLS для OCR).