# Запуск бенчмарков

Процесс запуска бенчмарка состоит из подготовки конфигурации и выполнения основного скрипта.

## 1. Подготовка конфигурации

Конфигурация эксперимента задается в CSV-файле (например, `user_config.csv`).

### Поля конфигурации:
*   `model_name`: Название модели (например, `Qwen2-VL-7B-Instruct`).
*   `dataset`: Название датасета из `data_dirs`.
*   `task_name`: Тип задачи (`VQA`, `Classification`).
*   `framework`: Фреймворк инференса (`vLLM`, `HuggingFace`).
*   `docker_image`: (Опционально) Кастомный образ.

## 2. Запуск через Orchestrator

Основная точка входа — скрипт `run_benchmark.py`.

```bash
uv run python run_benchmark.py --config user_config.csv
```

## 3. Мониторинг и результаты

После запуска Оркестратор:
1.  Создаст план выполнения.
2.  Запустит контейнеры для каждого этапа.
3.  **Real-time Monitoring**: Вы можете следить за прогрессом и потреблением ресурсов (GPU/RAM) через Web UI (по умолчанию порт `8050`).
4.  Сохранит ответы в `reports/answers/`, включая метрики производительности (TTFT, Latency).
5.  Сохранит метрики в `reports/metrics/`.
6.  Сгенерирует финальный отчет в формате Markdown.

## 4. Расширенная настройка промптов

VLMHyperBench поддерживает динамическое управление промптами через `PromptManager`. Вы можете настроить разные промпты для разных типов документов в конфигурационном файле:

```json
{
  "prompt_config": {
    "system_prompt": "Вы — помощник по распознаванию документов.",
    "type_mapping": {
      "passport": {
        "user_prompt": "Извлеки ФИО и номер из этого паспорта:"
      },
      "invoice": {
        "user_prompt": "Составь список товаров из счета:"
      }
    }
  }
}
```

## 5. Оптимизация промптов

Вы можете запустить процесс автоматической оптимизации промптов:

```bash
uv run python optimize_prompt.py --config config_prompt_optimization.json