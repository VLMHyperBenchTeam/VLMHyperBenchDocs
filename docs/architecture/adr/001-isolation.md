# ADR-001: Микросервисная архитектура и изоляция окружений

## Контекст
VLMHyperBench должен поддерживать оценку множества различных моделей (HuggingFace, vLLM, SGLang) и метрик. Разные модели могут требовать конфликтующих версий библиотек (CUDA, PyTorch, Transformers). Запуск всего в одном окружении приведет к "dependency hell".

## Решение
Принято решение использовать **строгую изоляцию этапов** (Inference, Eval, Report) через контейнеризацию.
*   Каждый этап запускается в собственном изолированном окружении (Docker Container, Singularity, Pod).
*   Управление жизненным циклом окружений делегируется абстракции `EnvManager`.

## Последствия
*   **Плюсы**: Полная изоляция зависимостей. Возможность параллельного запуска разных моделей на одной машине. Легкая масштабируемость на кластер.
*   **Минусы**: Оверхед на запуск контейнеров. Необходимость управления передачей данных между этапами (через Shared FS или S3).