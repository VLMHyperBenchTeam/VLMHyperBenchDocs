# ADR-001: Изоляция через контейнеризацию

## Контекст
VLM модели требуют специфичных версий библиотек (CUDA, PyTorch, Transformers, vLLM), которые часто конфликтуют между собой.

## Решение
Каждый этап выполнения (Inference, Evaluation) запускается в изолированном Docker-контейнере.

## Последствия
*   **Плюсы**: Отсутствие конфликтов зависимостей, воспроизводимость результатов, возможность запуска на разном железе.
*   **Минусы**: Накладные расходы на запуск контейнеров, необходимость управления образами.